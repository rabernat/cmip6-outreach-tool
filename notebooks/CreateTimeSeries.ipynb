{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CONSIDER REGRIDDING EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/intake/source/discovery.py:136: FutureWarning: The drivers ['stac-catalog', 'stac-collection', 'stac-item'] do not specify entry_points and were only discovered via a package scan. This may break in a future release of intake. The packages should be updated.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import intake\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# util.py is in the local directory\n",
    "# it contains code that is common across project notebooks\n",
    "# or routines that are too extensive and might otherwise clutter\n",
    "# the notebook design\n",
    "import util "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Settings for what to load into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_experiment_id = ['historical','ssp585']\n",
    "this_variable_id = 'tas'\n",
    "this_table_id = 'Amon'\n",
    "this_grid_label='gn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataDict():\n",
    "    if util.is_ncar_host():\n",
    "        col = intake.open_esm_datastore(\"../catalogs/glade-cmip6.json\")\n",
    "    else:\n",
    "        col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n",
    "    \n",
    "    cat = col.search(experiment_id=this_experiment_id, \\\n",
    "                     table_id=this_table_id, \\\n",
    "                     variable_id=this_variable_id, \\\n",
    "                     grid_label=this_grid_label)\n",
    "    dataset_info = cat.df\n",
    "    \n",
    "    dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False}, \n",
    "                                cdf_kwargs={'chunks': {}, 'decode_times': False})\n",
    "    #dset_dict.keys()\n",
    "    \n",
    "    source_ids = cat.df['source_id']\n",
    "    modelnames = list(set(source_ids))\n",
    "    \n",
    "    return dataset_info, dset_dict, modelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 28 group(s)\n"
     ]
    }
   ],
   "source": [
    "[dataset_info, dset_dict, modelnames]=createDataDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pandas Dataset\n",
    "\n",
    "Structure: rows = models; columns = scenarios; data = timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataFrame1():\n",
    "    df = pd.DataFrame(index=modelnames) \n",
    "    for expname in this_experiment_id:\n",
    "        experiment_id=expname\n",
    "        expvals = [None] * len(modelnames)\n",
    "        df[expname]=expvals\n",
    "        if expname=='historical':\n",
    "            activity_id='CMIP'\n",
    "        else:\n",
    "            activity_id='ScenarioMIP'\n",
    "        for modelname in modelnames:\n",
    "            source_id = modelname\n",
    "            dataset_info_subset = dataset_info[dataset_info['source_id']==source_id]\n",
    "            institution_id = list(set(dataset_info_subset['institution_id']))[0]\n",
    "            nametag = activity_id+'.'+institution_id+'.'+source_id+'.'+experiment_id+'.'+this_table_id+'.'+this_grid_label\n",
    "            if nametag in dset_dict:\n",
    "                if nametag=='CMIP.UA.MCM-UA-1-0.historical.Amon.gn':\n",
    "                    thisdata=dset_dict[nametag][this_variable_id].mean(dim=['latitude','longitude'])\n",
    "                else:\n",
    "                    thisdata=dset_dict[nametag][this_variable_id].mean(dim=['lat','lon'])\n",
    "            else:\n",
    "                thisdata='No data'\n",
    "            df[expname][modelname]=thisdata\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CreateDataFrame1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WANT TO MAKE A MULTIMODEL DATA STRUCTURE WITH DIMENSIONS OF: MODELNAME, TIME, SCENARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond this point, this is me trying to experiment with different data structures, etc. Doesn't really work/make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gregorian\n",
      "365_day\n",
      "noleap\n",
      "360_day\n",
      "noleap\n",
      "noleap\n",
      "365_day\n",
      "noleap\n",
      "noleap\n",
      "proleptic_gregorian\n",
      "proleptic_gregorian\n",
      "365_day\n",
      "gregorian\n",
      "noleap\n",
      "noleap\n",
      "365_day\n",
      "noleap\n",
      "360_day\n"
     ]
    }
   ],
   "source": [
    "modelnames_to_test_time_type = ['NESM3', 'BCC-CSM2-MR', 'NorCPM1', 'UKESM1-0-LL', 'GISS-E2-1-G-CC', 'SAM0-UNICON', 'CanESM5', 'MCM-UA-1-0', 'GISS-E2-1-G', 'MIROC6', 'MRI-ESM2-0', 'BCC-ESM1', 'MIROC-ES2L', 'CESM2-WACCM', 'CESM2', 'CAMS-CSM1-0', 'GISS-E2-1-H', 'HadGEM3-GC31-LL']\n",
    "for modelname in modelnames_to_test_time_type:\n",
    "    print(df['historical'][modelname]['time'].attrs['calendar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nametag='CMIP.NCAR.CESM2.historical.Amon.gn'\n",
    "thistime=dset_dict[nametag]['time']\n",
    "thisxr =    xr.DataArray(coords=[modelnames, thistime], dims=['modelnames', 'time'])\n",
    "thisxr[modelnames=='NorCPM1']=dset_dict[nametag]['tas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMIP.NCC.NorCPM1.historical.Amon.gn\n",
      "CMIP.CAMS.CAMS-CSM1-0.historical.Amon.gn\n",
      "CMIP.BCC.BCC-ESM1.historical.Amon.gn\n",
      "CMIP.UA.MCM-UA-1-0.historical.Amon.gn\n",
      "CMIP.NASA-GISS.GISS-E2-1-G-CC.historical.Amon.gn\n",
      "CMIP.BCC.BCC-CSM2-MR.historical.Amon.gn\n",
      "CMIP.MRI.MRI-ESM2-0.historical.Amon.gn\n",
      "CMIP.NUIST.NESM3.historical.Amon.gn\n",
      "CMIP.NASA-GISS.GISS-E2-1-G.historical.Amon.gn\n",
      "CMIP.NASA-GISS.GISS-E2-1-H.historical.Amon.gn\n",
      "CMIP.MOHC.HadGEM3-GC31-LL.historical.Amon.gn\n",
      "CMIP.MIROC.MIROC6.historical.Amon.gn\n",
      "CMIP.NCAR.CESM2.historical.Amon.gn\n",
      "CMIP.NCAR.CESM2-WACCM.historical.Amon.gn\n",
      "CMIP.CCCma.CanESM5.historical.Amon.gn\n",
      "CMIP.MIROC.MIROC-ES2L.historical.Amon.gn\n",
      "CMIP.SNU.SAM0-UNICON.historical.Amon.gn\n",
      "CMIP.MOHC.UKESM1-0-LL.historical.Amon.gn\n"
     ]
    }
   ],
   "source": [
    "experiment_id='historical'\n",
    "activity_id='CMIP'\n",
    "for modelname in modelnames:\n",
    "    source_id = modelname\n",
    "    dataset_info_subset = dataset_info[dataset_info['source_id']==source_id]\n",
    "    institution_id = list(set(dataset_info_subset['institution_id']))[0]\n",
    "    nametag = activity_id+'.'+institution_id+'.'+source_id+'.'+experiment_id+'.'+this_table_id+'.'+this_grid_label\n",
    "    if nametag in dset_dict:\n",
    "        print(nametag)\n",
    "        if nametag=='CMIP.UA.MCM-UA-1-0.historical.Amon.gn':\n",
    "            thisdata=dset_dict[nametag][this_variable_id].mean(dim=['latitude','longitude'])\n",
    "        else:\n",
    "            thisdata=dset_dict[nametag][this_variable_id].mean(dim=['lat','lon'])\n",
    "    else:\n",
    "        thisdata='No data'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
