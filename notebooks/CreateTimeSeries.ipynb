{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CONSIDER REGRIDDING EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import intake\n",
    "import pandas as pd\n",
    "\n",
    "# util.py is in the local directory\n",
    "# it contains code that is common across project notebooks\n",
    "# or routines that are too extensive and might otherwise clutter\n",
    "# the notebook design\n",
    "import util "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Settings for what to load into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_experiment_id = ['historical','ssp585']\n",
    "this_variable_id = 'tas'\n",
    "this_table_id = 'Amon'\n",
    "this_grid_label='gn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataDict():\n",
    "    if util.is_ncar_host():\n",
    "        col = intake.open_esm_datastore(\"../catalogs/glade-cmip6.json\")\n",
    "    else:\n",
    "        col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n",
    "    \n",
    "    cat = col.search(experiment_id=this_experiment_id, \\\n",
    "                     table_id=this_table_id, \\\n",
    "                     variable_id=this_variable_id, \\\n",
    "                     grid_label=this_grid_label)\n",
    "    dataset_info = cat.df\n",
    "    \n",
    "    dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False}, \n",
    "                                cdf_kwargs={'chunks': {}, 'decode_times': False})\n",
    "    #dset_dict.keys()\n",
    "    \n",
    "    source_ids = cat.df['source_id']\n",
    "    modelnames = list(set(source_ids))\n",
    "    \n",
    "    return dataset_info, dset_dict, modelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 28 group(s)\n"
     ]
    }
   ],
   "source": [
    "[dataset_info, dset_dict, modelnames]=createDataDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pandas Dataset\n",
    "\n",
    "Structure: rows = models; columns = scenarios; data = timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataFrame():\n",
    "    df = pd.DataFrame(index=modelnames) \n",
    "    for expname in this_experiment_id:\n",
    "        experiment_id=expname\n",
    "        expvals = []\n",
    "        if expname=='historical':\n",
    "            activity_id='CMIP'\n",
    "        else:\n",
    "            activity_id='ScenarioMIP'\n",
    "        for modelname in modelnames:\n",
    "            source_id = modelname\n",
    "            dataset_info_subset = dataset_info[dataset_info['source_id']==source_id]\n",
    "            institution_id = list(set(dataset_info_subset['institution_id']))[0]\n",
    "            nametag = activity_id+'.'+institution_id+'.'+source_id+'.'+experiment_id+'.'+this_table_id+'.'+this_grid_label\n",
    "            #print(nametag)\n",
    "            if nametag in dset_dict:\n",
    "                thisdata=dset_dict[nametag]\n",
    "                #print(np.shape(thisdata['time'].values))\n",
    "            else:\n",
    "                thisdata='No data'\n",
    "            expvals.append(thisdata)\n",
    "        df[expname]=expvals\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'tas' (member_id: 1, time: 1980, lat: 90, lon: 144)>\n",
       "dask.array<transpose, shape=(1, 1980, 90, 144), dtype=float32, chunksize=(1, 1980, 90, 144), chunktype=numpy.ndarray>\n",
       "Coordinates:\n",
       "  * lon        (lon) float64 1.25 3.75 6.25 8.75 ... 351.2 353.8 356.2 358.8\n",
       "  * time       (time) int64 0 708 1416 2148 ... 1442460 1443192 1443924 1444656\n",
       "  * lat        (lat) float64 -89.0 -87.0 -85.0 -83.0 ... 83.0 85.0 87.0 89.0\n",
       "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
       "Attributes:\n",
       "    cell_measures:  area: areacella\n",
       "    cell_methods:   area: time: mean\n",
       "    comment:        near-surface (usually, 2 meter) air temperature\n",
       "    long_name:      Near-Surface Air Temperature\n",
       "    standard_name:  air_temperature\n",
       "    units:          K"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CreateDataFrame()\n",
    "df['historical']['GISS-E2-1-G-CC'][this_variable_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Changed this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
